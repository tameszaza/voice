{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 1234\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "# Generator shared layers\n",
    "class GeneratorSharedLayers(nn.Module):\n",
    "    def __init__(self, ngf, nc):\n",
    "        super(GeneratorSharedLayers, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # First upsampling\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # Second upsampling\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # Third upsampling\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # Output layer\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Generator with unique input layer and shared layers\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc, shared_layers):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngf = ngf  # Store ngf as an instance variable\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(nz, ngf * 8 * 4 * 4),\n",
    "            nn.BatchNorm1d(ngf * 8 * 4 * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.shared_layers = shared_layers\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.input_layer(input)\n",
    "        x = x.view(-1, self.ngf * 8, 4, 4)  # Use self.ngf here\n",
    "        x = self.shared_layers(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator and Classifier shared layers\n",
    "class DiscriminatorSharedLayers(nn.Module):\n",
    "    def __init__(self, ndf, nc):\n",
    "        super(DiscriminatorSharedLayers, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input layer\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Hidden layer\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Hidden layer\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Hidden layer\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Discriminator with shared layers and unique output layers\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf, nc, shared_layers, num_gens):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ndf = ndf  # Store ndf as an instance variable\n",
    "        self.shared_layers = shared_layers\n",
    "        self.output_bin = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.output_mul = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 8, num_gens, 4, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.shared_layers(input)\n",
    "        output_bin = self.output_bin(x).view(-1, 1).squeeze(1)\n",
    "        output_mul = self.output_mul(x).squeeze()\n",
    "        return output_bin, output_mul\n",
    "\n",
    "# MGAN class encapsulating the training loop\n",
    "class MGAN:\n",
    "    def __init__(self,\n",
    "                 num_z=100,\n",
    "                 beta=0.5,\n",
    "                 num_gens=4,\n",
    "                 batch_size=128,\n",
    "                 z_prior=\"gaussian\",\n",
    "                 learning_rate=0.0002,\n",
    "                 num_epochs=50,\n",
    "                 img_size=(64, 64, 1),\n",
    "                 num_gen_feature_maps=64,\n",
    "                 num_dis_feature_maps=64,\n",
    "                 sample_dir=\"samples2\",\n",
    "                 device='cpu'):\n",
    "        self.beta = beta\n",
    "        self.num_z = num_z\n",
    "        self.num_gens = num_gens\n",
    "        self.batch_size = batch_size\n",
    "        self.z_prior = z_prior\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.img_size = img_size\n",
    "        self.ngf = num_gen_feature_maps\n",
    "        self.ndf = num_dis_feature_maps\n",
    "        self.sample_dir = sample_dir\n",
    "        self.device = device\n",
    "\n",
    "        self.history = {'d_loss': [], 'g_loss': []}\n",
    "\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Shared layers for Generators\n",
    "        self.shared_gen_layers = GeneratorSharedLayers(self.ngf, self.img_size[2]).to(self.device)\n",
    "        # List of Generators\n",
    "        self.generators = nn.ModuleList([\n",
    "            Generator(self.num_z, self.ngf, self.img_size[2], self.shared_gen_layers).to(self.device)\n",
    "            for _ in range(self.num_gens)\n",
    "        ])\n",
    "\n",
    "        # Shared layers for Discriminator\n",
    "        self.shared_dis_layers = DiscriminatorSharedLayers(self.ndf, self.img_size[2]).to(self.device)\n",
    "        # Discriminator\n",
    "        self.discriminator = Discriminator(self.ndf, self.img_size[2], self.shared_dis_layers, self.num_gens).to(self.device)\n",
    "\n",
    "        # Optimizers\n",
    "        # Combine parameters for shared layers and unique layers\n",
    "        self.optimizerD = optim.Adam(\n",
    "            list(self.discriminator.parameters()) + list(self.shared_dis_layers.parameters()),\n",
    "            lr=self.learning_rate, betas=(0.5, 0.999)\n",
    "        )\n",
    "        all_params = list(self.discriminator.parameters()) + list(self.shared_dis_layers.parameters())\n",
    "        print(f\"Unique Parameters: {len(set(id(p) for p in all_params))}\")\n",
    "        print(f\"Total Parameters: {len(all_params)}\")\n",
    "\n",
    "\n",
    "        # Generators have unique input layers but shared layers\n",
    "        gen_params = []\n",
    "        for gen in self.generators:\n",
    "            gen_params += list(gen.input_layer.parameters())\n",
    "        # Add shared generator layers\n",
    "        gen_params += list(self.shared_gen_layers.parameters())\n",
    "        self.optimizerG = optim.Adam(gen_params, lr=self.learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "        # Loss functions\n",
    "        self.criterion_bin = nn.BCELoss()\n",
    "        self.criterion_mul = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, trainloader):\n",
    "        fixed_noise = self._sample_z(self.num_gens * 16).to(self.device)\n",
    "\n",
    "        real_label = 1.0  # Ensure this is a float\n",
    "        fake_label = 0.0  # Ensure this is a float\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                ############################\n",
    "                # (1) Update D network\n",
    "                ###########################\n",
    "                self.discriminator.zero_grad()\n",
    "                real_images = data[0].to(self.device)\n",
    "                b_size = real_images.size(0)\n",
    "                label = torch.full((b_size,), real_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "                # Forward pass real batch through D\n",
    "                output_bin_real, _ = self.discriminator(real_images)\n",
    "                d_bin_real_loss = self.criterion_bin(output_bin_real, label)\n",
    "\n",
    "                # Generate fake images\n",
    "                fake_images = []\n",
    "                gen_labels = []\n",
    "                for idx, gen in enumerate(self.generators):\n",
    "                    z = self._sample_z(b_size // self.num_gens).to(self.device)\n",
    "                    gen_imgs = gen(z)\n",
    "                    fake_images.append(gen_imgs)\n",
    "                    gen_labels.append(torch.full((gen_imgs.size(0),), idx, dtype=torch.long, device=self.device))\n",
    "\n",
    "                fake_images = torch.cat(fake_images, 0)\n",
    "                gen_labels = torch.cat(gen_labels, 0)\n",
    "\n",
    "                label_fake = torch.full((fake_images.size(0),), fake_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "                # Forward pass fake batch through D\n",
    "                output_bin_fake, output_mul_fake = self.discriminator(fake_images.detach())\n",
    "                d_bin_fake_loss = self.criterion_bin(output_bin_fake, label_fake)\n",
    "                d_mul_loss = self.criterion_mul(output_mul_fake, gen_labels)\n",
    "\n",
    "                # Sum all discriminator losses\n",
    "                d_loss = d_bin_real_loss + d_bin_fake_loss + d_mul_loss * self.beta\n",
    "                d_loss.backward()\n",
    "                self.optimizerD.step()\n",
    "\n",
    "                ############################\n",
    "                # (2) Update G network\n",
    "                ###########################\n",
    "                for gen in self.generators:\n",
    "                    gen.zero_grad()\n",
    "                self.shared_gen_layers.zero_grad()\n",
    "\n",
    "                # We want the generator to fool the discriminator\n",
    "                label = torch.full((fake_images.size(0),), real_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "                output_bin_fake, output_mul_fake = self.discriminator(fake_images)\n",
    "                g_bin_loss = self.criterion_bin(output_bin_fake, label)\n",
    "                g_mul_loss = self.criterion_mul(output_mul_fake, gen_labels) * self.beta\n",
    "\n",
    "                g_loss = g_bin_loss + g_mul_loss\n",
    "                g_loss.backward()\n",
    "                self.optimizerG.step()\n",
    "\n",
    "                # Save losses for plotting\n",
    "                self.history['d_loss'].append(d_loss.item())\n",
    "                self.history['g_loss'].append(g_loss.item())\n",
    "\n",
    "            # Output training stats\n",
    "            print('[%d/%d] d_loss: %.4f | g_loss: %.4f'\n",
    "                  % (epoch+1, self.num_epochs,\n",
    "                     d_loss.item(),\n",
    "                     g_loss.item()))\n",
    "\n",
    "            # Save samples every few epochs\n",
    "            if (epoch+1) % 5 == 0:\n",
    "                self._save_samples(epoch+1, fixed_noise)\n",
    "\n",
    "        # After training, plot the learning curves\n",
    "        self._plot_history()\n",
    "\n",
    "    def _sample_z(self, size):\n",
    "        if self.z_prior == \"uniform\":\n",
    "            return torch.rand(size, self.num_z) * 2 - 1  # Uniform between [-1, 1]\n",
    "        else:\n",
    "            return torch.randn(size, self.num_z)\n",
    "\n",
    "    def _save_samples(self, epoch, fixed_noise):\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(self.sample_dir):\n",
    "            os.makedirs(self.sample_dir)\n",
    "\n",
    "        # Generate images\n",
    "        with torch.no_grad():\n",
    "            fake_images_list = []\n",
    "            for idx, gen in enumerate(self.generators):\n",
    "                noise = fixed_noise[idx * 16: (idx + 1) * 16]\n",
    "                gen.eval()\n",
    "                fake_images = gen(noise.to(self.device))\n",
    "                gen.train()\n",
    "                fake_images_list.append(fake_images)\n",
    "\n",
    "            # Concatenate images from all generators\n",
    "            fake_images = torch.cat(fake_images_list, 0)\n",
    "\n",
    "            # Normalize images to range [0, 1]\n",
    "            fake_images = (fake_images + 1) / 2.0\n",
    "\n",
    "            # Save the images\n",
    "            sample_path = os.path.join(self.sample_dir, 'epoch_{:04d}.png'.format(epoch))\n",
    "            vutils.save_image(fake_images, sample_path, nrow=16, padding=2, normalize=True)\n",
    "\n",
    "    def _plot_history(self):\n",
    "        # Plot the learning curves\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"Loss During Training\")\n",
    "        plt.plot(self.history['d_loss'], label=\"D Loss\")\n",
    "        plt.plot(self.history['g_loss'], label=\"G Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Unique Parameters: 14\n",
      "Total Parameters: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  return disable_fn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Execute the main function\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m mgan_model \u001b[38;5;241m=\u001b[39m MGAN(\n\u001b[1;32m     35\u001b[0m     num_z\u001b[38;5;241m=\u001b[39mnum_z,\n\u001b[1;32m     36\u001b[0m     beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mmgan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 220\u001b[0m, in \u001b[0;36mMGAN.fit\u001b[0;34m(self, trainloader)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Sum all discriminator losses\u001b[39;00m\n\u001b[1;32m    219\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m d_bin_real_loss \u001b[38;5;241m+\u001b[39m d_bin_fake_loss \u001b[38;5;241m+\u001b[39m d_mul_loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta\n\u001b[0;32m--> 220\u001b[0m \u001b[43md_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizerD\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# (2) Update G network\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m###########################\u001b[39;00m\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Main function to train MGAN\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    num_z = 100  # Size of z latent vector (i.e. size of generator input)\n",
    "    beta = 0.5   # Diversity parameter beta\n",
    "    num_gens = 10  # Number of generators\n",
    "    batch_size = 128  # Batch size\n",
    "    z_prior = \"gaussian\"  # Prior distribution of the noise ('uniform' or 'gaussian')\n",
    "    learning_rate = 0.0002  # Learning rate for optimizers\n",
    "    num_epochs = 50  # Number of training epochs\n",
    "    image_size = 64  # Spatial size of training images\n",
    "    num_channels = 1  # Number of channels in the training images. For MNIST, it's 1\n",
    "    num_gen_feature_maps = 64\n",
    "    num_dis_feature_maps = 64\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Create the dataset\n",
    "    dataroot = './data'\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalize the images to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    trainset = torchvision.datasets.MNIST(root=dataroot, train=True,\n",
    "                                          download=True, transform=transform)\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                             shuffle=True, num_workers=2)\n",
    "\n",
    "    # Create the MGAN model\n",
    "    mgan_model = MGAN(\n",
    "        num_z=num_z,\n",
    "        beta=beta,\n",
    "        num_gens=num_gens,\n",
    "        batch_size=batch_size,\n",
    "        z_prior=z_prior,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=num_epochs,\n",
    "        img_size=(image_size, image_size, num_channels),\n",
    "        num_gen_feature_maps=num_gen_feature_maps,\n",
    "        num_dis_feature_maps=num_dis_feature_maps,\n",
    "        sample_dir=\"samples3\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    mgan_model.fit(trainloader)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
