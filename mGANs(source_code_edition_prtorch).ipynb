{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (120x131072 and 8192x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 394\u001b[0m\n\u001b[1;32m    376\u001b[0m model \u001b[38;5;241m=\u001b[39m MGAN(\n\u001b[1;32m    377\u001b[0m     num_z\u001b[38;5;241m=\u001b[39mnum_z,\n\u001b[1;32m    378\u001b[0m     beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     sample_by_gen_fp\u001b[38;5;241m=\u001b[39msample_by_gen_fp,\n\u001b[1;32m    391\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6789\u001b[39m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 253\u001b[0m, in \u001b[0;36mMGAN.fit\u001b[0;34m(self, trainloader)\u001b[0m\n\u001b[1;32m    251\u001b[0m fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG(z)\n\u001b[1;32m    252\u001b[0m label_fake \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((fake\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),), fake_label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 253\u001b[0m d_bin_g_logits, d_mul_g_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m d_bin_g_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(d_bin_g_logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), label_fake)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Binary loss\u001b[39;00m\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 167\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs(x)\n\u001b[1;32m    166\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mview(h\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 167\u001b[0m d_bin_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m d_mul_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_multi(h)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d_bin_logits, d_mul_logits\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/tameszaza/My Passport/ml/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (120x131072 and 8192x1)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Define utility functions and classes\n",
    "class Prior(object):\n",
    "    def __init__(self, prior_type):\n",
    "        self.type = prior_type\n",
    "\n",
    "    def sample(self, shape):\n",
    "        if self.type == \"uniform\":\n",
    "            return torch.rand(shape) * 2 - 1  # Uniform between -1 and 1\n",
    "        else:\n",
    "            return torch.randn(shape)\n",
    "\n",
    "def conv_out_size_same(size, stride):\n",
    "    return int(math.ceil(float(size) / float(stride)))\n",
    "\n",
    "def create_image_grid(x, img_size, tile_shape):\n",
    "    # x is a tensor of shape [N, C, H, W], values in [0, 1]\n",
    "    assert (x.size(0) == tile_shape[0] * tile_shape[1])\n",
    "    x = x.permute(0, 2, 3, 1)  # N, H, W, C\n",
    "    x = x.cpu().numpy()\n",
    "    if img_size[2] == 1:\n",
    "        x = x.squeeze(-1)  # Remove last channel dimension for grayscale\n",
    "        img = np.zeros((img_size[0] * tile_shape[0] + tile_shape[0] - 1,\n",
    "                        img_size[1] * tile_shape[1] + tile_shape[1] - 1))\n",
    "    else:\n",
    "        img = np.zeros((img_size[0] * tile_shape[0] + tile_shape[0] - 1,\n",
    "                        img_size[1] * tile_shape[1] + tile_shape[1] - 1,\n",
    "                        3))\n",
    "\n",
    "    for t in range(x.shape[0]):\n",
    "        i, j = t // tile_shape[1], t % tile_shape[1]\n",
    "        img_i_start = i * img_size[0] + i\n",
    "        img_i_end = (i + 1) * img_size[0] + i\n",
    "        img_j_start = j * img_size[1] + j\n",
    "        img_j_end = (j + 1) * img_size[1] + j\n",
    "        img[img_i_start:img_i_end, img_j_start:img_j_end] = x[t]\n",
    "\n",
    "    return img\n",
    "\n",
    "# Define the Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_z, num_gen_feature_maps, img_size, num_conv_layers, num_gens, g_batch_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.num_z = num_z\n",
    "        self.num_gen_feature_maps = num_gen_feature_maps\n",
    "        self.img_size = img_size\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_gens = num_gens\n",
    "        self.g_batch_size = g_batch_size\n",
    "\n",
    "        # Compute the size after the first linear layer\n",
    "        out_size = [(int(img_size[0] / (2 ** num_conv_layers)),\n",
    "                     int(img_size[1] / (2 ** num_conv_layers)),\n",
    "                     num_gen_feature_maps * (2 ** (num_conv_layers - 1)))]\n",
    "        for i in range(1, num_conv_layers):\n",
    "            out_size = [(out_size[0][0] * 2,\n",
    "                         out_size[0][1] * 2,\n",
    "                         out_size[0][2] // 2)] + out_size\n",
    "\n",
    "        self.out_size = out_size\n",
    "\n",
    "        # Create linear layers for each generator\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(num_gens):\n",
    "            self.linears.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(num_z, out_size[0][0] * out_size[0][1] * out_size[0][2]),\n",
    "                    nn.BatchNorm1d(out_size[0][0] * out_size[0][1] * out_size[0][2]),\n",
    "                    nn.ReLU(True)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Deconvolutional layers\n",
    "        deconv_modules = []\n",
    "        in_channels = out_size[0][2]\n",
    "        for i in range(num_conv_layers):\n",
    "            if i < num_conv_layers - 1:\n",
    "                out_channels = out_size[i+1][2]\n",
    "                deconv_modules.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU(True)\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "            else:\n",
    "                deconv_modules.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.ConvTranspose2d(in_channels, img_size[2], kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "                        nn.Tanh()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        self.deconvs = nn.Sequential(*deconv_modules)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z_split = torch.split(z, self.g_batch_size, dim=0)\n",
    "        h0_list = []\n",
    "        for i in range(self.num_gens):\n",
    "            h0 = self.linears[i](z_split[i])\n",
    "            h0 = h0.view(self.g_batch_size, self.out_size[0][2], self.out_size[0][0], self.out_size[0][1])\n",
    "            h0_list.append(h0)\n",
    "        h0 = torch.cat(h0_list, dim=0)\n",
    "        output = self.deconvs(h0)\n",
    "        return output\n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_dis_feature_maps, img_size, num_conv_layers, num_gens):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_dis_feature_maps = num_dis_feature_maps\n",
    "        self.img_size = img_size\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_gens = num_gens\n",
    "\n",
    "        # Build the discriminator network\n",
    "        modules = []\n",
    "        in_channels = img_size[2]\n",
    "        feature_map_sizes = []\n",
    "        for i in range(num_conv_layers):\n",
    "            out_channels = num_dis_feature_maps * (2 ** i)\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=2, padding=2),\n",
    "                    nn.BatchNorm2d(out_channels) if i != 0 else nn.Identity(),\n",
    "                    nn.LeakyReLU(0.2, inplace=True)\n",
    "                )\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "\n",
    "            # Compute output size\n",
    "            if i == 0:\n",
    "                h_out = conv_out_size_same(self.img_size[0], stride=2)\n",
    "            else:\n",
    "                h_out = conv_out_size_same(h_out, stride=2)\n",
    "            feature_map_sizes.append(h_out)\n",
    "\n",
    "        self.convs = nn.Sequential(*modules)\n",
    "\n",
    "        # Manually compute the fc_input_dim\n",
    "        final_feature_map_size = h_out\n",
    "        self.fc_input_dim = in_channels * final_feature_map_size * final_feature_map_size\n",
    "\n",
    "        # Output layers\n",
    "        self.fc = nn.Linear(self.fc_input_dim, 1)\n",
    "        self.fc_multi = nn.Linear(self.fc_input_dim, num_gens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.convs(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        d_bin_logits = self.fc(h)\n",
    "        d_mul_logits = self.fc_multi(h)\n",
    "        return d_bin_logits, d_mul_logits\n",
    "\n",
    "# Define the MGAN class\n",
    "class MGAN(object):\n",
    "    \"\"\"Mixture Generative Adversarial Nets implemented in PyTorch\"\"\"\n",
    "    def __init__(self,\n",
    "                 num_z=128,\n",
    "                 beta=1.0,\n",
    "                 num_gens=4,\n",
    "                 d_batch_size=64,\n",
    "                 g_batch_size=32,\n",
    "                 z_prior=\"uniform\",\n",
    "                 learning_rate=0.0002,\n",
    "                 img_size=(32, 32, 1),  # Changed to (32, 32, 1) for MNIST\n",
    "                 num_conv_layers=3,\n",
    "                 num_gen_feature_maps=128,\n",
    "                 num_dis_feature_maps=128,\n",
    "                 num_epochs=25000,\n",
    "                 sample_fp=None,\n",
    "                 sample_by_gen_fp=None,\n",
    "                 random_seed=6789):\n",
    "\n",
    "        self.beta = beta\n",
    "        self.num_z = num_z\n",
    "        self.num_gens = num_gens\n",
    "        self.d_batch_size = d_batch_size\n",
    "        self.g_batch_size = g_batch_size\n",
    "        self.z_prior = Prior(z_prior)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.img_size = img_size\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_gen_feature_maps = num_gen_feature_maps\n",
    "        self.num_dis_feature_maps = num_dis_feature_maps\n",
    "        self.sample_fp = sample_fp\n",
    "        self.sample_by_gen_fp = sample_by_gen_fp\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self._init()\n",
    "\n",
    "    def _init(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "        # Initialize Generator and Discriminator\n",
    "        self.G = Generator(self.num_z, self.num_gen_feature_maps, self.img_size,\n",
    "                           self.num_conv_layers, self.num_gens, self.g_batch_size).to(self.device)\n",
    "        self.D = Discriminator(self.num_dis_feature_maps, self.img_size,\n",
    "                               self.num_conv_layers, self.num_gens).to(self.device)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizerD = optim.Adam(self.D.parameters(), lr=self.learning_rate, betas=(0.5, 0.999))\n",
    "        self.optimizerG = optim.Adam(self.G.parameters(), lr=self.learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "        # Loss functions\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.criterion_multi = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, trainloader):\n",
    "        real_label = 1\n",
    "        fake_label = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                ############################\n",
    "                # (1) Update D network\n",
    "                ###########################\n",
    "                self.D.zero_grad()\n",
    "                real_cpu = data[0].to(self.device)\n",
    "                batch_size = real_cpu.size(0)\n",
    "                label = torch.full((batch_size,), real_label, dtype=torch.float, device=self.device)\n",
    "\n",
    "                d_bin_x_logits, d_mul_x_logits = self.D(real_cpu)\n",
    "                d_bin_x_loss = self.criterion(d_bin_x_logits.view(-1), label)\n",
    "\n",
    "                # Generate fake data\n",
    "                if self.z_prior.type == \"uniform\":\n",
    "                    z = torch.rand(self.g_batch_size * self.num_gens, self.num_z, device=self.device) * 2 - 1\n",
    "                else:\n",
    "                    z = torch.randn(self.g_batch_size * self.num_gens, self.num_z, device=self.device)\n",
    "\n",
    "                fake = self.G(z)\n",
    "                label_fake = torch.full((fake.size(0),), fake_label, dtype=torch.float, device=self.device)\n",
    "                d_bin_g_logits, d_mul_g_logits = self.D(fake.detach())\n",
    "                d_bin_g_loss = self.criterion(d_bin_g_logits.view(-1), label_fake)\n",
    "\n",
    "                # Binary loss\n",
    "                d_bin_loss = d_bin_x_loss + d_bin_g_loss\n",
    "\n",
    "                # Multiclass loss\n",
    "                arr = np.array([i // self.g_batch_size for i in range(self.g_batch_size * self.num_gens)])\n",
    "                d_mul_labels = torch.from_numpy(arr).long().to(self.device)\n",
    "                d_mul_loss = self.criterion_multi(d_mul_g_logits, d_mul_labels)\n",
    "\n",
    "                # Total discriminator loss\n",
    "                d_loss = d_bin_loss + d_mul_loss\n",
    "\n",
    "                d_loss.backward()\n",
    "                self.optimizerD.step()\n",
    "\n",
    "                ############################\n",
    "                # (2) Update G network\n",
    "                ###########################\n",
    "                self.G.zero_grad()\n",
    "                label.fill_(real_label)\n",
    "                d_bin_g_logits, d_mul_g_logits = self.D(fake)\n",
    "                g_bin_loss = self.criterion(d_bin_g_logits.view(-1), label_fake.fill_(real_label))\n",
    "                g_mul_loss = self.beta * self.criterion_multi(d_mul_g_logits, d_mul_labels)\n",
    "\n",
    "                g_loss = g_bin_loss + g_mul_loss\n",
    "                g_loss.backward()\n",
    "                self.optimizerG.step()\n",
    "\n",
    "            print('[%d/%d] D_loss: %.4f G_loss: %.4f' % (epoch+1, self.num_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "            # Save samples\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                self._samples(self.sample_fp.format(epoch=epoch+1))\n",
    "                self._samples_by_gen(self.sample_by_gen_fp.format(epoch=epoch+1))\n",
    "\n",
    "    def _generate(self, num_samples=100):\n",
    "        with torch.no_grad():\n",
    "            batch_size = self.g_batch_size * self.num_gens\n",
    "            num = ((num_samples - 1) // batch_size + 1) * batch_size\n",
    "            if self.z_prior.type == \"uniform\":\n",
    "                z = torch.rand(num, self.num_z, device=self.device) * 2 - 1\n",
    "            else:\n",
    "                z = torch.randn(num, self.num_z, device=self.device)\n",
    "            x = []\n",
    "            for i in range(0, num, batch_size):\n",
    "                z_batch = z[i:i+batch_size]\n",
    "                x_batch = self.G(z_batch).cpu()\n",
    "                x.append(x_batch)\n",
    "            x = torch.cat(x, dim=0)\n",
    "            idx = np.random.permutation(num)[:num_samples]\n",
    "            x = x[idx]\n",
    "            x = (x + 1) / 2\n",
    "            return x\n",
    "\n",
    "    def _samples(self, filepath, tile_shape=(10, 10)):\n",
    "        if not os.path.exists(os.path.dirname(filepath)):\n",
    "            os.makedirs(os.path.dirname(filepath))\n",
    "\n",
    "        num_samples = tile_shape[0] * tile_shape[1]\n",
    "        x = self._generate(num_samples)\n",
    "        imgs = create_image_grid(x, img_size=self.img_size, tile_shape=tile_shape)\n",
    "        if self.img_size[2] == 1:\n",
    "            plt.imsave(filepath, imgs, cmap='gray')\n",
    "        else:\n",
    "            plt.imsave(filepath, imgs)\n",
    "\n",
    "    def _samples_by_gen(self, filepath):\n",
    "        if not os.path.exists(os.path.dirname(filepath)):\n",
    "            os.makedirs(os.path.dirname(filepath))\n",
    "\n",
    "        num_samples = self.num_gens * 10\n",
    "        tile_shape = (self.num_gens, 10)\n",
    "\n",
    "        x = []\n",
    "        for _ in range(10):\n",
    "            if self.z_prior.type == \"uniform\":\n",
    "                z = torch.rand(self.g_batch_size * self.num_gens, self.num_z, device=self.device) * 2 - 1\n",
    "            else:\n",
    "                z = torch.randn(self.g_batch_size * self.num_z, device=self.device)\n",
    "            x_batch = self.G(z).cpu()\n",
    "            x.append(x_batch)\n",
    "        x = torch.cat(x, dim=0)\n",
    "        x = (x + 1) / 2\n",
    "\n",
    "        imgs = create_image_grid(x, img_size=self.img_size, tile_shape=tile_shape)\n",
    "        if self.img_size[2] == 1:\n",
    "            plt.imsave(filepath, imgs, cmap='gray')\n",
    "        else:\n",
    "            plt.imsave(filepath, imgs)\n",
    "\n",
    "# Main function to run the MGAN model\n",
    "if __name__ == '__main__':\n",
    "    # Set parameters\n",
    "    num_z = 100\n",
    "    beta = 0.01\n",
    "    num_gens = 10\n",
    "    d_batch_size = 64\n",
    "    g_batch_size = 12\n",
    "    z_prior = \"uniform\"\n",
    "    learning_rate = 0.0002\n",
    "    num_conv_layers = 3\n",
    "    num_gen_feature_maps = 128\n",
    "    num_dis_feature_maps = 128\n",
    "    num_epochs = 50  # Reduced for testing purposes\n",
    "    sample_fp = \"samples/samples_{epoch:04d}.png\"\n",
    "    sample_by_gen_fp = \"samples_by_gen/samples_{epoch:04d}.png\"\n",
    "\n",
    "    # Load data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=d_batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    # Initialize model\n",
    "    model = MGAN(\n",
    "        num_z=num_z,\n",
    "        beta=beta,\n",
    "        num_gens=num_gens,\n",
    "        d_batch_size=d_batch_size,\n",
    "        g_batch_size=g_batch_size,\n",
    "        z_prior=z_prior,\n",
    "        learning_rate=learning_rate,\n",
    "        img_size=(32, 32, 1),  # Updated for MNIST\n",
    "        num_conv_layers=num_conv_layers,\n",
    "        num_gen_feature_maps=num_gen_feature_maps,\n",
    "        num_dis_feature_maps=num_dis_feature_maps,\n",
    "        num_epochs=num_epochs,\n",
    "        sample_fp=sample_fp,\n",
    "        sample_by_gen_fp=sample_by_gen_fp,\n",
    "        random_seed=6789)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(trainloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
