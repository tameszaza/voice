{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 6789\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "# Generator shared layers\n",
    "class GeneratorSharedLayers(nn.Module):\n",
    "    def __init__(self, ngf, nc):\n",
    "        super(GeneratorSharedLayers, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # First upsampling\n",
    "            nn.ConvTranspose1d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # Second upsampling\n",
    "            nn.ConvTranspose1d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # Third upsampling\n",
    "            nn.ConvTranspose1d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # Output layer\n",
    "            nn.ConvTranspose1d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Generator with unique input layer and shared layers\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc, shared_layers):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngf = ngf  # Store ngf as an instance variable\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(nz, ngf * 8 * 4 * 4),\n",
    "            nn.BatchNorm1d(ngf * 8 * 4 * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.shared_layers = shared_layers\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.input_layer(input)\n",
    "        x = x.view(-1, self.ngf * 8, 4, 4)  # Use self.ngf here\n",
    "        x = self.shared_layers(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator and Classifier shared layers\n",
    "class DiscriminatorSharedLayers(nn.Module):\n",
    "    def __init__(self, ndf, nc):\n",
    "        super(DiscriminatorSharedLayers, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input layer\n",
    "            nn.Conv1d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Hidden layer\n",
    "            nn.Conv1d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Hidden layer\n",
    "            nn.Conv1d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Hidden layer\n",
    "            nn.Conv1d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Discriminator with shared layers and unique output layers\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf, nc, shared_layers, num_gens):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ndf = ndf  # Store ndf as an instance variable\n",
    "        self.shared_layers = shared_layers\n",
    "        self.output_bin = nn.Sequential(\n",
    "            nn.Conv1d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.output_mul = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 8, num_gens, 4, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.shared_layers(input)\n",
    "        output_bin = self.output_bin(x).view(-1, 1).squeeze(1)\n",
    "        output_mul = self.output_mul(x).squeeze()\n",
    "        return output_bin, output_mul\n",
    "\n",
    "# MGAN class encapsulating the training loop\n",
    "class MGAN:\n",
    "    def __init__(self,\n",
    "                 num_z=100,\n",
    "                 beta=0.5,\n",
    "                 num_gens=4,\n",
    "                 batch_size=128,\n",
    "                 z_prior=\"gaussian\",\n",
    "                 learning_rate=0.0002,\n",
    "                 num_epochs=50,\n",
    "                 img_size=(64, 64, 1),\n",
    "                 num_gen_feature_maps=64,\n",
    "                 num_dis_feature_maps=64,\n",
    "                 sample_dir=\"samples\",\n",
    "                 device='cpu'):\n",
    "        self.beta = beta\n",
    "        self.num_z = num_z\n",
    "        self.num_gens = num_gens\n",
    "        self.batch_size = batch_size\n",
    "        self.z_prior = z_prior\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.img_size = img_size\n",
    "        self.ngf = num_gen_feature_maps\n",
    "        self.ndf = num_dis_feature_maps\n",
    "        self.sample_dir = sample_dir\n",
    "        self.device = device\n",
    "\n",
    "        self.history = {'d_loss': [], 'g_loss': []}\n",
    "\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Shared layers for Generators\n",
    "        self.shared_gen_layers = GeneratorSharedLayers(self.ngf, self.img_size[2]).to(self.device)\n",
    "        # List of Generators\n",
    "        self.generators = nn.ModuleList([\n",
    "            Generator(self.num_z, self.ngf, self.img_size[2], self.shared_gen_layers).to(self.device)\n",
    "            for _ in range(self.num_gens)\n",
    "        ])\n",
    "\n",
    "        # Shared layers for Discriminator\n",
    "        self.shared_dis_layers = DiscriminatorSharedLayers(self.ndf, self.img_size[2]).to(self.device)\n",
    "        # Discriminator\n",
    "        self.discriminator = Discriminator(self.ndf, self.img_size[2], self.shared_dis_layers, self.num_gens).to(self.device)\n",
    "\n",
    "        # Optimizers\n",
    "        # Combine parameters for shared layers and unique layers\n",
    "        self.optimizerD = optim.Adam(\n",
    "            list(self.discriminator.parameters()) + list(self.shared_dis_layers.parameters()),\n",
    "            lr=self.learning_rate, betas=(0.5, 0.999)\n",
    "        )\n",
    "        all_params = list(self.discriminator.parameters()) + list(self.shared_dis_layers.parameters())\n",
    "        print(f\"Unique Parameters: {len(set(id(p) for p in all_params))}\")\n",
    "        print(f\"Total Parameters: {len(all_params)}\")\n",
    "\n",
    "\n",
    "        # Generators have unique input layers but shared layers\n",
    "        gen_params = []\n",
    "        for gen in self.generators:\n",
    "            gen_params += list(gen.input_layer.parameters())\n",
    "        # Add shared generator layers\n",
    "        gen_params += list(self.shared_gen_layers.parameters())\n",
    "        self.optimizerG = optim.Adam(gen_params, lr=self.learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "        # Loss functions\n",
    "        self.criterion_bin = nn.BCELoss()\n",
    "        self.criterion_mul = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, trainloader):\n",
    "        fixed_noise = self._sample_z(self.num_gens * 16).to(self.device)\n",
    "\n",
    "        real_label = 1.0  # Ensure this is a float\n",
    "        fake_label = 0.0  # Ensure this is a float\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                ############################\n",
    "                # (1) Update D network\n",
    "                ###########################\n",
    "                self.discriminator.zero_grad()\n",
    "                real_images = data[0].to(self.device)\n",
    "                b_size = real_images.size(0)\n",
    "                label = torch.full((b_size,), real_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "                # Forward pass real batch through D\n",
    "                output_bin_real, _ = self.discriminator(real_images)\n",
    "                d_bin_real_loss = self.criterion_bin(output_bin_real, label)\n",
    "\n",
    "                # Generate fake images\n",
    "                fake_images = []\n",
    "                gen_labels = []\n",
    "                for idx, gen in enumerate(self.generators):\n",
    "                    z = self._sample_z(b_size // self.num_gens).to(self.device)\n",
    "                    gen_imgs = gen(z)\n",
    "                    fake_images.append(gen_imgs)\n",
    "                    gen_labels.append(torch.full((gen_imgs.size(0),), idx, dtype=torch.long, device=self.device))\n",
    "\n",
    "                fake_images = torch.cat(fake_images, 0)\n",
    "                gen_labels = torch.cat(gen_labels, 0)\n",
    "\n",
    "                label_fake = torch.full((fake_images.size(0),), fake_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "                # Forward pass fake batch through D\n",
    "                output_bin_fake, output_mul_fake = self.discriminator(fake_images.detach())\n",
    "                d_bin_fake_loss = self.criterion_bin(output_bin_fake, label_fake)\n",
    "                d_mul_loss = self.criterion_mul(output_mul_fake, gen_labels)\n",
    "\n",
    "                # Sum all discriminator losses\n",
    "                d_loss = d_bin_real_loss + d_bin_fake_loss + d_mul_loss * self.beta\n",
    "                d_loss.backward()\n",
    "                self.optimizerD.step()\n",
    "\n",
    "                ############################\n",
    "                # (2) Update G network\n",
    "                ###########################\n",
    "                for gen in self.generators:\n",
    "                    gen.zero_grad()\n",
    "                self.shared_gen_layers.zero_grad()\n",
    "\n",
    "                # We want the generator to fool the discriminator\n",
    "                label = torch.full((fake_images.size(0),), real_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "                output_bin_fake, output_mul_fake = self.discriminator(fake_images)\n",
    "                g_bin_loss = self.criterion_bin(output_bin_fake, label)\n",
    "                g_mul_loss = self.criterion_mul(output_mul_fake, gen_labels) * self.beta\n",
    "\n",
    "                g_loss = g_bin_loss + g_mul_loss\n",
    "                g_loss.backward()\n",
    "                self.optimizerG.step()\n",
    "\n",
    "                # Save losses for plotting\n",
    "                self.history['d_loss'].append(d_loss.item())\n",
    "                self.history['g_loss'].append(g_loss.item())\n",
    "\n",
    "            # Output training stats\n",
    "            print('[%d/%d] d_loss: %.4f | g_loss: %.4f'\n",
    "                  % (epoch+1, self.num_epochs,\n",
    "                     d_loss.item(),\n",
    "                     g_loss.item()))\n",
    "\n",
    "            # Save samples every few epochs\n",
    "            if (epoch+1) % 5 == 0:\n",
    "                self._save_samples(epoch+1, fixed_noise)\n",
    "\n",
    "        # After training, plot the learning curves\n",
    "        self._plot_history()\n",
    "\n",
    "    def _sample_z(self, size):\n",
    "        if self.z_prior == \"uniform\":\n",
    "            return torch.rand(size, self.num_z) * 2 - 1  # Uniform between [-1, 1]\n",
    "        else:\n",
    "            return torch.randn(size, self.num_z)\n",
    "\n",
    "    def _save_samples(self, epoch, fixed_noise):\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(self.sample_dir):\n",
    "            os.makedirs(self.sample_dir)\n",
    "\n",
    "        # Generate images\n",
    "        with torch.no_grad():\n",
    "            fake_images_list = []\n",
    "            for idx, gen in enumerate(self.generators):\n",
    "                noise = fixed_noise[idx * 16: (idx + 1) * 16]\n",
    "                gen.eval()\n",
    "                fake_images = gen(noise.to(self.device))\n",
    "                gen.train()\n",
    "                fake_images_list.append(fake_images)\n",
    "\n",
    "            # Concatenate images from all generators\n",
    "            fake_images = torch.cat(fake_images_list, 0)\n",
    "\n",
    "            # Normalize images to range [0, 1]\n",
    "            fake_images = (fake_images + 1) / 2.0\n",
    "\n",
    "            # Save the images\n",
    "            sample_path = os.path.join(self.sample_dir, 'epoch_{:04d}.png'.format(epoch))\n",
    "            vutils.save_image(fake_images, sample_path, nrow=16, padding=2, normalize=True)\n",
    "\n",
    "    def _plot_history(self):\n",
    "        # Plot the learning curves\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"Loss During Training\")\n",
    "        plt.plot(self.history['d_loss'], label=\"D Loss\")\n",
    "        plt.plot(self.history['g_loss'], label=\"G Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, dataloader):\n",
    "    fixed_noise = self._sample_z(self.num_gens * 16).to(self.device)\n",
    "    real_label = 1.0\n",
    "    fake_label = 0.0\n",
    "\n",
    "    for epoch in range(self.num_epochs):\n",
    "        for i, (real_images,) in enumerate(dataloader):\n",
    "            self.discriminator.zero_grad()\n",
    "            real_images = real_images.to(self.device)\n",
    "            b_size = real_images.size(0)\n",
    "            label = torch.full((b_size,), real_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "            # Forward pass real batch through D\n",
    "            output_bin_real, _ = self.discriminator(real_images)\n",
    "            d_bin_real_loss = self.criterion_bin(output_bin_real, label)\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_images = []\n",
    "            gen_labels = []\n",
    "            for idx, gen in enumerate(self.generators):\n",
    "                z = self._sample_z(b_size // self.num_gens).to(self.device)\n",
    "                gen_imgs = gen(z)\n",
    "                fake_images.append(gen_imgs)\n",
    "                gen_labels.append(torch.full((gen_imgs.size(0),), idx, dtype=torch.long, device=self.device))\n",
    "\n",
    "            fake_images = torch.cat(fake_images, 0)\n",
    "            gen_labels = torch.cat(gen_labels, 0)\n",
    "\n",
    "            output_bin_fake, output_mul_fake = self.discriminator(fake_images.detach())\n",
    "            d_bin_fake_loss = self.criterion_bin(output_bin_fake, torch.full((fake_images.size(0),), fake_label, device=self.device, dtype=torch.float))\n",
    "            d_mul_loss = self.criterion_mul(output_mul_fake, gen_labels)\n",
    "\n",
    "            d_loss = d_bin_real_loss + d_bin_fake_loss + d_mul_loss * self.beta\n",
    "            d_loss.backward()\n",
    "            self.optimizerD.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{self.num_epochs}] D Loss: {d_loss.item()}\")\n",
    "\n",
    "    print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "def load_flac(file_path, target_sr=16000):\n",
    "    \"\"\"Load a FLAC audio file and resample it to the target sample rate.\"\"\"\n",
    "    audio, sr = librosa.load(file_path, sr=target_sr)  # Waveform convertig\n",
    "    audio = audio / np.max(np.abs(audio))  # Normalize to [-1, 1]\n",
    "    return audio\n",
    "\n",
    "def load_librispeech_data(root_dir, target_sr=16000):\n",
    "    \"\"\"Load all FLAC files from the LibriSpeech dataset.\"\"\"\n",
    "    flac_files = glob(os.path.join(root_dir, '**', '*.flac'), recursive=True)\n",
    "    dataset = []\n",
    "\n",
    "    for file in flac_files:\n",
    "        audio = load_flac(file, target_sr)\n",
    "        dataset.append(audio)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "#preprocess\n",
    "\n",
    "def pad_or_trim(audio, target_length=32000): #GAN need to fix lenght\n",
    "    \"\"\"Pad or trim audio to the target length.\"\"\"\n",
    "    if len(audio) < target_length:\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "    else:\n",
    "        audio = audio[:target_length]\n",
    "    return audio\n",
    "\n",
    "def preprocess_dataset(root_dir, target_sr=16000, target_length=32000):\n",
    "    \"\"\"Load and preprocess all audio files in the dataset.\"\"\"\n",
    "    flac_files = glob(os.path.join(root_dir, '**', '*.flac'), recursive=True)\n",
    "    dataset = []\n",
    "\n",
    "    for file in flac_files:\n",
    "        audio = load_flac(file)\n",
    "        audio = pad_or_trim(audio, target_length)\n",
    "        \n",
    "        # # Optional: Split into frequency bands or segments if needed\n",
    "        # low_band, high_band = split_into_bands(audio)\n",
    "        # dataset.append((low_band, high_band))  # For multiple generators\n",
    "\n",
    "        dataset.append(audio)  # For single generator or raw audio input\n",
    "    dataset = torch.tensor(dataset, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "    return TensorDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded 2703 audio files.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Execute the main function\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 26\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(audio_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(audio_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m audio files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (audio,) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(audio_dataset[:\u001b[38;5;241m3\u001b[39m]):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(audio)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 1)"
     ]
    }
   ],
   "source": [
    "# Main function to train MGAN\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    num_z = 100\n",
    "    beta = 0.5\n",
    "    num_gens = 4\n",
    "    batch_size = 32\n",
    "    z_prior = \"gaussian\"\n",
    "    learning_rate = 0.0002\n",
    "    num_epochs = 10\n",
    "    num_gen_feature_maps = 64\n",
    "    num_dis_feature_maps = 64\n",
    "    audio_length = 32000  # Length of audio samples\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Load and preprocess audio dataset\n",
    "    data_dir = r'C:\\Users\\Admin\\Documents\\voice\\voice\\data\\LibriSpeech\\LibriSpeech\\dev-clean'\n",
    "    audio_dataset = preprocess_dataset(data_dir, target_length=audio_length)\n",
    "    \n",
    "    # Create DataLoader for the audio dataset\n",
    "    dataloader = DataLoader(audio_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(f\"Loaded {len(audio_dataset)} audio files.\")\n",
    "    for i, (audio,) in enumerate(audio_dataset[:3]):\n",
    "        print(f\"Audio file {i+1}:\")\n",
    "        print(f\"  - Type: {type(audio)}\")\n",
    "        print(f\"  - Shape: {audio.shape}\")\n",
    "        print(f\"  - First 10 samples: {audio[:10]}\\n\")\n",
    "    \n",
    "    # Create the MGAN model\n",
    "    mgan_model = MGAN(\n",
    "        num_z=num_z,\n",
    "        beta=beta,\n",
    "        num_gens=num_gens,\n",
    "        batch_size=batch_size,\n",
    "        z_prior=z_prior,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=num_epochs,\n",
    "        num_gen_feature_maps=num_gen_feature_maps,\n",
    "        num_dis_feature_maps=num_dis_feature_maps,\n",
    "        sample_dir=\"samples\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Train the model using the DataLoader\n",
    "    mgan_model.fit(dataloader)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
