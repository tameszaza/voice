{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, TensorDataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 6789\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "# Generator shared layers\n",
    "class GeneratorSharedLayers(nn.Module):\n",
    "    def __init__(self, ngf, nc):\n",
    "        super(GeneratorSharedLayers, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Generator with unique input layer and shared layers\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc, shared_layers, mel_bins, time_frames):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngf = ngf\n",
    "        self.mel_bins = mel_bins\n",
    "        self.time_frames = time_frames\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(nz, ngf * 8 * (mel_bins // 8) * (time_frames // 8)),\n",
    "            nn.BatchNorm1d(ngf * 8 * (mel_bins // 8) * (time_frames // 8)),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.shared_layers = shared_layers\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.input_layer(input)\n",
    "        x = x.view(-1, self.ngf * 8, self.mel_bins // 8, self.time_frames // 8)\n",
    "        x = self.shared_layers(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator shared layers\n",
    "class DiscriminatorSharedLayers(nn.Module):\n",
    "    def __init__(self, ndf, nc):\n",
    "        super(DiscriminatorSharedLayers, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Discriminator with shared layers and unique output layers\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf, nc, shared_layers, num_gens, mel_bins, time_frames):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.shared_layers = shared_layers\n",
    "        self.output_bin = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 8, 1, (mel_bins // 16, time_frames // 16), 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.output_mul = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 8, num_gens, (mel_bins // 16, time_frames // 16), 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.shared_layers(input)\n",
    "        output_bin = self.output_bin(x).view(-1, 1).squeeze(1)\n",
    "        output_mul = self.output_mul(x).squeeze()\n",
    "        return output_bin, output_mul\n",
    "\n",
    "# MGAN class encapsulating the training loop\n",
    "class MGAN:\n",
    "    def __init__(self, num_z, beta, num_gens, batch_size, z_prior, learning_rate,\n",
    "                 num_epochs, img_size, num_gen_feature_maps, num_dis_feature_maps,\n",
    "                 sample_dir, device):\n",
    "        self.num_z = num_z\n",
    "        self.beta = beta\n",
    "        self.num_gens = num_gens\n",
    "        self.batch_size = batch_size\n",
    "        self.z_prior = z_prior\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.img_size = img_size\n",
    "        self.ngf = num_gen_feature_maps\n",
    "        self.ndf = num_dis_feature_maps\n",
    "        self.sample_dir = sample_dir\n",
    "        self.device = device\n",
    "\n",
    "        self.mel_bins, self.num_frames, self.num_channels = img_size\n",
    "        self.history = {'d_loss': [], 'g_loss': []}\n",
    "\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        mel_bins, time_frames, num_channels = self.img_size\n",
    "\n",
    "        self.shared_gen_layers = GeneratorSharedLayers(self.ngf, num_channels).to(self.device)\n",
    "        self.generators = nn.ModuleList([\n",
    "            Generator(self.num_z, self.ngf, num_channels, self.shared_gen_layers, mel_bins, time_frames).to(self.device)\n",
    "            for _ in range(self.num_gens)\n",
    "        ])\n",
    "        self.shared_dis_layers = DiscriminatorSharedLayers(self.ndf, num_channels).to(self.device)\n",
    "        self.discriminator = Discriminator(self.ndf, num_channels, self.shared_dis_layers, self.num_gens, mel_bins, time_frames).to(self.device)\n",
    "\n",
    "        self.optimizerD = optim.Adam(\n",
    "            list(self.discriminator.parameters()) + list(self.shared_dis_layers.parameters()),\n",
    "            lr=self.learning_rate, betas=(0.5, 0.999)\n",
    "        )\n",
    "        gen_params = [param for gen in self.generators for param in gen.input_layer.parameters()]\n",
    "        gen_params += list(self.shared_gen_layers.parameters())\n",
    "        self.optimizerG = optim.Adam(gen_params, lr=self.learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "        self.criterion_bin = nn.BCELoss()\n",
    "        self.criterion_mul = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, trainloader):\n",
    "        fixed_noise = self._sample_z(self.num_gens * 16).to(self.device)\n",
    "\n",
    "        real_label = 1.0\n",
    "        fake_label = 0.0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i, data in enumerate(trainloader):\n",
    "                real_images = data[0].to(self.device)\n",
    "                b_size = real_images.size(0)\n",
    "                label_real = torch.full((b_size,), real_label, device=self.device)\n",
    "                label_fake = torch.full((b_size,), fake_label, device=self.device)\n",
    "\n",
    "                output_bin_real, _ = self.discriminator(real_images)\n",
    "                d_bin_real_loss = self.criterion_bin(output_bin_real, label_real)\n",
    "\n",
    "                # Generate fake images and labels\n",
    "                fake_images = []\n",
    "                gen_labels = []\n",
    "                for idx, gen in enumerate(self.generators):\n",
    "                    z = self._sample_z(b_size // self.num_gens).to(self.device)\n",
    "                    fake_imgs = gen(z)\n",
    "                    fake_images.append(fake_imgs)\n",
    "                    gen_labels.append(torch.full((fake_imgs.size(0),), idx, dtype=torch.long, device=self.device))\n",
    "\n",
    "                fake_images = torch.cat(fake_images, 0)\n",
    "                gen_labels = torch.cat(gen_labels, 0)\n",
    "\n",
    "                # Get discriminator output for fake images\n",
    "                output_bin_fake, output_mul_fake = self.discriminator(fake_images.detach())\n",
    "\n",
    "                # Create labels with the correct size\n",
    "                output_size = output_bin_fake.size()  # Match the shape of the output\n",
    "                label_real = torch.full(output_size, real_label, device=self.device, dtype=torch.float)\n",
    "                label_fake = torch.full(output_size, fake_label, device=self.device, dtype=torch.float)\n",
    "\n",
    "                # Compute losses\n",
    "                d_bin_fake_loss = self.criterion_bin(output_bin_fake, label_fake)\n",
    "                d_mul_loss = self.criterion_mul(output_mul_fake.view(-1, self.num_gens), gen_labels)\n",
    "                self.optimizerD.step()\n",
    "\n",
    "                for gen in self.generators:\n",
    "                    gen.zero_grad()\n",
    "                self.shared_gen_layers.zero_grad()\n",
    "\n",
    "                label_real = torch.full((fake_images.size(0),), real_label, device=self.device)\n",
    "                output_bin_fake, output_mul_fake = self.discriminator(fake_images)\n",
    "                g_bin_loss = self.criterion_bin(output_bin_fake, label_real)\n",
    "                g_mul_loss = self.criterion_mul(output_mul_fake.view(-1, self.num_gens), gen_labels) * self.beta\n",
    "\n",
    "                g_loss = g_bin_loss + g_mul_loss\n",
    "                g_loss.backward()\n",
    "                self.optimizerG.step()\n",
    "\n",
    "                self.history['d_loss'].append(d_loss.item())\n",
    "                self.history['g_loss'].append(g_loss.item())\n",
    "\n",
    "            print(f\"[{epoch+1}/{self.num_epochs}] d_loss: {d_loss.item():.4f} | g_loss: {g_loss.item():.4f}\")\n",
    "            if (epoch+1) % 5 == 0:\n",
    "                self._save_samples(epoch+1, fixed_noise)\n",
    "\n",
    "        self._plot_history()\n",
    "\n",
    "    def _sample_z(self, size):\n",
    "        if self.z_prior == \"uniform\":\n",
    "            return torch.rand(size, self.num_z) * 2 - 1\n",
    "        return torch.randn(size, self.num_z)\n",
    "\n",
    "    def _save_samples(self, epoch, fixed_noise):\n",
    "        with torch.no_grad():\n",
    "            fake_images = []\n",
    "            for idx, gen in enumerate(self.generators):\n",
    "                noise = fixed_noise[idx * 16:(idx + 1) * 16].to(self.device)\n",
    "                gen.eval()\n",
    "                fake_imgs = gen(noise)\n",
    "                gen.train()\n",
    "                fake_images.append(fake_imgs)\n",
    "\n",
    "            fake_images = torch.cat(fake_images, 0)\n",
    "            fake_images = (fake_images + 1) / 2.0\n",
    "            os.makedirs(self.sample_dir, exist_ok=True)\n",
    "            sample_path = os.path.join(self.sample_dir, f\"epoch_{epoch:04d}.png\")\n",
    "            vutils.save_image(fake_images, sample_path, nrow=16, padding=2, normalize=True)\n",
    "            print(f\"Saved samples to {sample_path}\")\n",
    "\n",
    "    def _plot_history(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.history['d_loss'], label=\"D Loss\")\n",
    "        plt.plot(self.history['g_loss'], label=\"G Loss\")\n",
    "        plt.title(\"Loss During Training\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def librispeech_to_mel(root_dir, target_sr=16000, n_mels=64, n_fft=1024, hop_length=512, target_length=128):\n",
    "    \"\"\"\n",
    "    Convert raw LibriSpeech audio files to Mel spectrograms and return a TensorDataset.\n",
    "    \"\"\"\n",
    "    from glob import glob\n",
    "\n",
    "    flac_files = glob(os.path.join(root_dir, '**', '*.flac'), recursive=True)\n",
    "    mel_spectrograms = []  # Initialize list to store Mel spectrograms\n",
    "\n",
    "    if len(flac_files) == 0:\n",
    "        raise ValueError(f\"No FLAC files found in directory: {root_dir}\")\n",
    "\n",
    "    for file in flac_files:\n",
    "        try:\n",
    "            # Load the audio file\n",
    "            audio, sr = librosa.load(file, sr=target_sr)\n",
    "            # Normalize audio to range [-1, 1]\n",
    "            audio = audio / np.max(np.abs(audio))\n",
    "            \n",
    "            # Convert to Mel spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "            \n",
    "            # Convert to dB scale\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            \n",
    "            # Ensure the Mel spectrogram has a fixed length\n",
    "            if mel_spec_db.shape[1] < target_length:\n",
    "                # Pad if shorter\n",
    "                pad_width = target_length - mel_spec_db.shape[1]\n",
    "                mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                # Trim if longer\n",
    "                mel_spec_db = mel_spec_db[:, :target_length]\n",
    "\n",
    "            # Add channel dimension and append to list\n",
    "            mel_tensor = torch.tensor(mel_spec_db, dtype=torch.float32).unsqueeze(0)  # Add channel dim\n",
    "            mel_spectrograms.append(mel_tensor)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    if len(mel_spectrograms) == 0:\n",
    "        raise ValueError(\"No valid audio files were processed into Mel spectrograms.\")\n",
    "\n",
    "    # Stack into a single tensor\n",
    "    mel_spectrograms = torch.stack(mel_spectrograms)  # Shape: [num_samples, 1, n_mels, target_length]\n",
    "    return TensorDataset(mel_spectrograms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mgan_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmgan_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MGAN  \u001b[38;5;66;03m# Import the MGAN class\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myour_dataset_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m librispeech_to_mel  \u001b[38;5;66;03m# Your dataset preprocessing function\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Hyperparameters\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mgan_model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from mgan_model import MGAN  # Import the MGAN class\n",
    "from your_dataset_loader import librispeech_to_mel  # Your dataset preprocessing function\n",
    "\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    num_z = 100\n",
    "    beta = 0.5\n",
    "    num_gens = 10\n",
    "    batch_size = 32\n",
    "    z_prior = \"gaussian\"\n",
    "    learning_rate = 0.0002\n",
    "    num_epochs = 50\n",
    "\n",
    "    # Spectrogram dimensions\n",
    "    mel_bins = 64\n",
    "    num_frames = 128\n",
    "    num_channels = 1\n",
    "    img_size = (mel_bins, num_frames, num_channels)\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Dataset preprocessing\n",
    "    data_dir = r'data\\LibriSpeech\\LibriSpeech\\dev-clean'\n",
    "    print(\"Preprocessing dataset into Mel spectrograms...\")\n",
    "    mel_dataset = librispeech_to_mel(data_dir, target_sr=16000, n_mels=mel_bins, target_length=num_frames)\n",
    "    print(f\"Dataset size: {len(mel_dataset)}\")\n",
    "\n",
    "    # DataLoader\n",
    "    dataloader = DataLoader(mel_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize MGAN\n",
    "    mgan_model = MGAN(\n",
    "        num_z=num_z,\n",
    "        beta=beta,\n",
    "        num_gens=num_gens,\n",
    "        batch_size=batch_size,\n",
    "        z_prior=z_prior,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=num_epochs,\n",
    "        img_size=img_size,\n",
    "        num_gen_feature_maps=64,\n",
    "        num_dis_feature_maps=64,\n",
    "        sample_dir=\"samples\",\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    mgan_model.fit(dataloader)\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
