{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# constants (unchanged)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "SR            = 22_050          # sample-rate used in your pipeline\n",
    "SEGMENT_LEN   = 4 * SR\n",
    "N_MELS        = 128\n",
    "N_FFT         = 1024\n",
    "HOP_LENGTH    = 512\n",
    "TARGET_FRAMES = 128\n",
    "MAX_PAD_RATIO = 0.65            # discard if >65 % padding\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# helper functions (unchanged)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "def load_audio(path: Path) -> np.ndarray:\n",
    "    audio, sr = sf.read(str(path))\n",
    "    if audio.ndim > 1:\n",
    "        audio = audio.mean(axis=1)\n",
    "    if sr != SR:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=SR)\n",
    "    return audio.astype(np.float32)\n",
    "\n",
    "def wav_to_logmel(wav: np.ndarray) -> np.ndarray:\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=wav, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS, power=2.0,\n",
    "    )\n",
    "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "    if logmel.shape[1] != TARGET_FRAMES:\n",
    "        logmel = resize(\n",
    "            logmel, (N_MELS, TARGET_FRAMES),\n",
    "            mode=\"reflect\", preserve_range=True, anti_aliasing=True\n",
    "        )\n",
    "    return logmel.astype(np.float32)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# NEW – end-to-end preprocessing with safe atomic write + fixed dB range\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "def preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir: str | Path,\n",
    "    out_npy_file: str | Path,\n",
    "    out_stats_json: str | Path | None = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert all .wav under `wav_dir` to (1,128,128) log-Mel tensors,\n",
    "    stack them → (N,1,128,128), clamp to [-80,0] dB, then min-max normalise\n",
    "    into [-1,1], and save both the array and the fixed-range stats (JSON).\n",
    "    \"\"\"\n",
    "    wav_dir = Path(wav_dir)\n",
    "    specs: list[np.ndarray] = []\n",
    "\n",
    "    # gather all 4-second segments as log-Mel patches\n",
    "    for wav_path in wav_dir.rglob(\"*.wav\"):\n",
    "        audio = load_audio(wav_path)\n",
    "        n_chunks = math.ceil(len(audio) / SEGMENT_LEN)\n",
    "\n",
    "        for i in range(n_chunks):\n",
    "            chunk = audio[i*SEGMENT_LEN:(i+1)*SEGMENT_LEN]\n",
    "            missing = SEGMENT_LEN - len(chunk)\n",
    "\n",
    "            if missing > 0:\n",
    "                pad_ratio = missing / SEGMENT_LEN\n",
    "                if pad_ratio > MAX_PAD_RATIO:\n",
    "                    continue  # skip overly short tail\n",
    "                chunk = np.pad(chunk, (0, missing), mode=\"constant\")\n",
    "\n",
    "            specs.append(wav_to_logmel(chunk)[None, ...])  # (1,128,128)\n",
    "\n",
    "    if not specs:\n",
    "        raise RuntimeError(f\"No usable segments found in {wav_dir}\")\n",
    "\n",
    "    data = np.stack(specs, axis=0)  # → (N,1,128,128) float32\n",
    "\n",
    "    # ── Fixed dB-range normalisation to [-1,1] ────────────────────\n",
    "    floor_db = -80.0\n",
    "    ceil_db  =   0.0\n",
    "\n",
    "    # clamp to [floor_db, ceil_db]\n",
    "    data = np.clip(data, floor_db, ceil_db)\n",
    "    # map [floor_db, ceil_db] → [0,1]\n",
    "    data = (data - floor_db) / (ceil_db - floor_db)\n",
    "    # then map [0,1] → [-1,1]\n",
    "    data = data * 2.0 - 1.0\n",
    "\n",
    "    # ── Atomic save – write to tmp then rename ─────────────────────\n",
    "    out_npy_file = Path(out_npy_file)\n",
    "    out_npy_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(\n",
    "        dir=out_npy_file.parent, suffix=\".npy\", delete=False\n",
    "    ) as tmp:\n",
    "        np.save(tmp.name, data)\n",
    "        tmp.flush()\n",
    "        os.fsync(tmp.fileno())\n",
    "    os.replace(tmp.name, out_npy_file)  # atomic on POSIX\n",
    "    # ── Save fixed-range stats for later reference ────────────────\n",
    "    # if out_stats_json is None:\n",
    "    #     out_stats_json = out_npy_file.with_suffix(\".json\")\n",
    "    # with open(out_stats_json, \"w\") as f:\n",
    "    #     json.dump({\n",
    "    #         \"db_floor\": floor_db,\n",
    "    #         \"db_ceil\":  ceil_db,\n",
    "    #         \"scaled_min\": -1.0,\n",
    "    #         \"scaled_max\":  1.0,\n",
    "    #         \"shape\":      data.shape,\n",
    "    #         \"dtype\":      \"float32\"\n",
    "    #     }, f, indent=2)\n",
    "\n",
    "    # # Final verification – cheap header read\n",
    "    # hdr = np.lib.format.read_array_header_1_0(open(out_npy_file, \"rb\"))\n",
    "    # assert hdr[0] == data.shape and hdr[2] == data.dtype, \"save corrupted!\"\n",
    "\n",
    "    print(f\"✅ Saved {data.shape[0]} segments → {out_npy_file}\")\n",
    "    print(f\"   Stats  dB range=[{floor_db},{ceil_db}]  JSON→ {out_stats_json}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_full_band_melgan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/fake/normalized_ljspeech_full_band_melgan.npy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_hifiGAN\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/fake/normalized_ljspeech_hifiGAN.npy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_melgan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/fake/normalized_ljspeech_melgan.npy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_melgan_large\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/fake/normalized_ljspeech_melgan_large.npy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_multi_band_melgan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/fake/normalized_ljspeech_multi_band_melgan.npy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_parallel_wavegan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/fake/normalized_ljspeech_parallel_wavegan.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_waveglow\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/fake/normalized_ljspeech_waveglow.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/real/wavs\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake128/normalized_real.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.load(\"/home/ml/Documents/voice/ResData/wavefake128_split/test/real.npy\",\n",
    "              mmap_mode='r')\n",
    "print(arr.shape, arr.dtype, arr.min(), arr.max())\n",
    "# (21537, 1, 128, 128) float32 0.0 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# CONFIG – change only these three lines\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# CONFIG – change only these three lines\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "IN_FILE    = \"/home/ml/Documents/voice/ResData/wavefake/real.npy\"\n",
    "OUT_FILE   = \"/home/ml/Documents/voice/ResData/wavefake/normalized_real.npy\"\n",
    "PARAMS_NPZ = \"train_raw_norm_params.npz\"\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.format import open_memmap      # ← new import\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) mem-map the big array (no RAM spike)\n",
    "x_map = np.load(IN_FILE, mmap_mode=\"r\")\n",
    "print(\"Shape :\", x_map.shape, \"dtype :\", x_map.dtype)\n",
    "\n",
    "# 2) global extrema on the *training* split\n",
    "x_min, x_max = float(x_map.min()), float(x_map.max())\n",
    "print(f\"global min {x_min:.3f}   max {x_max:.3f}\")\n",
    "denom = x_max - x_min\n",
    "assert denom > 1e-12, \"min and max are equal – check the data!\"\n",
    "\n",
    "# 3) create **proper .npy file with header** that is also a mem-map\n",
    "out_shape = x_map.shape\n",
    "out_map   = open_memmap(\n",
    "    OUT_FILE,\n",
    "    mode=\"w+\",                 # create for read/write\n",
    "    dtype=np.float32,\n",
    "    shape=out_shape\n",
    ")\n",
    "print(\"Writing to\", OUT_FILE, \"…\")\n",
    "\n",
    "# 4) normalise in mini-batches\n",
    "BATCH = 512\n",
    "N = out_shape[0]\n",
    "\n",
    "for start in range(0, N, BATCH):\n",
    "    end   = min(start + BATCH, N)\n",
    "    slice = x_map[start:end].astype(np.float32)\n",
    "    slice = 2.0 * (slice - x_min) / denom - 1.0     # → (-1 … +1)\n",
    "    out_map[start:end] = slice\n",
    "    if (start // BATCH) % 50 == 0:\n",
    "        print(f\"processed {end}/{N}\")\n",
    "\n",
    "out_map.flush()          # ensure data hits disk\n",
    "print(\"✓ finished writing\", OUT_FILE)\n",
    "\n",
    "# 5) store scale params\n",
    "np.savez(PARAMS_NPZ, xmin=x_min, xmax=x_max)\n",
    "print(\"✓ saved scale params to\", PARAMS_NPZ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# CONFIG  –  adjust the three paths below\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "VAL_IN   = \"/home/ml/Documents/voice/ResData/log-mel-eval-aggregate/real.npy\"             # raw   (N,1,H,W) log-Mel values\n",
    "VAL_OUT  = \"/home/ml/Documents/voice/ResData/log-mel-eval-aggregate/normalized_real.npy\"  # scaled copy  –1…+1  (same shape)\n",
    "PARAMS   = \"train_raw_norm_params.npz\"  # the file you saved earlier\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) load the two scale parameters learned on *training*\n",
    "params = np.load(PARAMS)\n",
    "xmin, xmax = float(params[\"xmin\"]), float(params[\"xmax\"])\n",
    "denom      = xmax - xmin\n",
    "assert denom > 1e-12, \"xmin == xmax – scale parameters look wrong\"\n",
    "\n",
    "print(f\"using xmin={xmin:.3f}  xmax={xmax:.3f}  (denom={denom:.3f})\")\n",
    "\n",
    "# 2) memory-map the big validation array (read-only)\n",
    "x_val = np.load(VAL_IN, mmap_mode=\"r\")           # shape (N,1,H,W)\n",
    "print(\"val shape :\", x_val.shape, \"dtype :\", x_val.dtype)\n",
    "\n",
    "# 3) create an output mem-map with the same shape, float32\n",
    "val_norm = np.memmap(VAL_OUT, dtype=np.float32,\n",
    "                     mode=\"w+\", shape=x_val.shape)\n",
    "\n",
    "# 4) stream-normalise in mini-batches to keep RAM low\n",
    "BATCH = 512                                       # tune per GPU/RAM\n",
    "N      = x_val.shape[0]\n",
    "\n",
    "for start in range(0, N, BATCH):\n",
    "    end = min(start + BATCH, N)\n",
    "    chunk = x_val[start:end].astype(np.float32)    # load small slice\n",
    "\n",
    "    # Min-max transform → (-1 … +1)\n",
    "    chunk = 2.0 * (chunk - xmin) / denom - 1.0\n",
    "\n",
    "    val_norm[start:end] = chunk                    # write back\n",
    "    if (start // BATCH) % 50 == 0:\n",
    "        print(f\"processed {end}/{N}\")\n",
    "\n",
    "val_norm.flush()   # make sure data is written to disk\n",
    "print(\"✓ saved normalised validation file to\", VAL_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ───────────────────────── CONFIG ──────────────────────────\n",
    "# 1) Where are the raw log-Mel .npy files?\n",
    "SRC_DIR = Path('/home/ml/Documents/voice/ResData/log-mel-data-train')      # <── change me\n",
    "\n",
    "# 2) Where is the file that holds xmin / xmax?\n",
    "PARAMS_FILE = Path('/home/ml/Documents/voice/ResPreprocess/train_raw_norm_params.npz')\n",
    "\n",
    "# (No need to edit anything below unless you want to)\n",
    "# ───────────────────────────────────────────────────────────\n",
    "\n",
    "# → Destination folder:  normalized_<old-folder-name>\n",
    "DST_DIR = SRC_DIR.parent / f'normalized_{SRC_DIR.name}'\n",
    "DST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Normalised files will be saved to:  {DST_DIR}\\n')\n",
    "\n",
    "# ── Load global min / max ─────────────────────────────────\n",
    "with np.load(PARAMS_FILE) as f:\n",
    "    xmin = f['xmin'].item()   # scalar, e.g. -80.0\n",
    "    xmax = f['xmax'].item()   # scalar, e.g. -1.1e-5\n",
    "\n",
    "denom = xmax - xmin\n",
    "if np.isclose(denom, 0):\n",
    "    raise ValueError('xmax and xmin are identical — cannot normalise.')\n",
    "\n",
    "print(f'Using xmin = {xmin}, xmax = {xmax}  ➜  scale = {denom}\\n')\n",
    "\n",
    "# ── Walk through every .npy (sub-folders included) ─────────\n",
    "for npy_path in tqdm(list(SRC_DIR.rglob('*.npy')), desc='Normalising'):\n",
    "    x = np.load(npy_path)\n",
    "\n",
    "    # min-max:   x' = (x − xmin) / (xmax − xmin)\n",
    "    x_norm = (x - xmin) / denom\n",
    "    x_norm = np.clip(x_norm, 0.0, 1.0).astype(np.float32)   # keep in [0,1]\n",
    "\n",
    "    # Mirror the original folder structure inside DST_DIR\n",
    "    out_path = DST_DIR / npy_path.relative_to(SRC_DIR)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(out_path, x_norm)\n",
    "\n",
    "print('\\n✅  All files normalised.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ───────────────────────── CONFIG ──────────────────────────\n",
    "# 1) Where are the raw log-Mel .npy files?\n",
    "SRC_DIR = Path('/home/ml/Documents/voice/ResData/log-mel-eval/fake')      # <── change me\n",
    "\n",
    "# 2) Where is the file that holds xmin / xmax?\n",
    "PARAMS_FILE = Path('/home/ml/Documents/voice/ResPreprocess/train_raw_norm_params.npz')\n",
    "\n",
    "# (No need to edit anything below unless you want to)\n",
    "# ───────────────────────────────────────────────────────────\n",
    "\n",
    "# → Destination folder:  normalized_<old-folder-name>\n",
    "DST_DIR = SRC_DIR.parent / f'normalized_{SRC_DIR.name}'\n",
    "DST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Normalised files will be saved to:  {DST_DIR}\\n')\n",
    "\n",
    "# ── Load global min / max ─────────────────────────────────\n",
    "with np.load(PARAMS_FILE) as f:\n",
    "    xmin = f['xmin'].item()   # scalar, e.g. -80.0\n",
    "    xmax = f['xmax'].item()   # scalar, e.g. -1.1e-5\n",
    "\n",
    "denom = xmax - xmin\n",
    "if np.isclose(denom, 0):\n",
    "    raise ValueError('xmax and xmin are identical — cannot normalise.')\n",
    "\n",
    "print(f'Using xmin = {xmin}, xmax = {xmax}  ➜  scale = {denom}\\n')\n",
    "\n",
    "# ── Walk through every .npy (sub-folders included) ─────────\n",
    "for npy_path in tqdm(list(SRC_DIR.rglob('*.npy')), desc='Normalising'):\n",
    "    x = np.load(npy_path)\n",
    "\n",
    "    # min-max:   x' = (x − xmin) / (xmax − xmin)\n",
    "    x_norm = (x - xmin) / denom\n",
    "    x_norm = np.clip(x_norm, 0.0, 1.0).astype(np.float32)   # keep in [0,1]\n",
    "\n",
    "    # Mirror the original folder structure inside DST_DIR\n",
    "    out_path = DST_DIR / npy_path.relative_to(SRC_DIR)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(out_path, x_norm)\n",
    "\n",
    "print('\\n✅  All files normalised.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_npy_file(\n",
    "    input_path: str,\n",
    "    train_path: str,\n",
    "    test_path: str,\n",
    "    train_ratio: float = 0.8,\n",
    "    seed: int | None = None\n",
    ") -> tuple[tuple[int,...], tuple[int,...]]:\n",
    "    \"\"\"\n",
    "    Split a .npy dataset into train/test and save them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : str\n",
    "        Path to the original .npy file (shape: N×1×128×128).\n",
    "    train_path : str\n",
    "        Where to save the training split (will be .npy).\n",
    "    test_path : str\n",
    "        Where to save the test split (will be .npy).\n",
    "    train_ratio : float, default=0.8\n",
    "        Fraction of samples to go into the training set.\n",
    "    seed : int or None\n",
    "        RNG seed for reproducible shuffling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_shape : tuple\n",
    "        Shape of the saved training array.\n",
    "    test_shape : tuple\n",
    "        Shape of the saved test array.\n",
    "    \"\"\"\n",
    "    data = np.load(input_path)\n",
    "    N = data.shape[0]\n",
    "    m = int(N * train_ratio)\n",
    "\n",
    "    # shuffle indices\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    train_idx = idx[:m]\n",
    "    test_idx  = idx[m:]\n",
    "\n",
    "    train_data = data[train_idx]\n",
    "    test_data  = data[test_idx]\n",
    "\n",
    "    np.save(train_path, train_data)\n",
    "    np.save(test_path,  test_data)\n",
    "\n",
    "    return train_data.shape, test_data.shape\n",
    "\n",
    "# Example usage:\n",
    "# train_shape, test_shape = split_npy_file(\n",
    "#     'all_data.npy',\n",
    "#     'train_data.npy',\n",
    "#     'test_data.npy',\n",
    "#     train_ratio=0.8,\n",
    "#     seed=42\n",
    "# )\n",
    "# print(f\"Train: {train_shape}, Test: {test_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35369, 1, 64, 64), Test: (8843, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_full_band_melgan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/fake/ljspeech_full_band_melgan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/fake/ljspeech_full_band_melgan.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35311, 1, 64, 64), Test: (8828, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_hifiGAN.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/fake/ljspeech_hifiGAN.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/fake/ljspeech_hifiGAN.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35369, 1, 64, 64), Test: (8843, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_melgan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/fake/ljspeech_melgan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/fake/ljspeech_melgan.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35369, 1, 64, 64), Test: (8843, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_parallel_wavegan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/fake/ljspeech_parallel_wavegan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/fake/ljspeech_parallel_wavegan.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35369, 1, 64, 64), Test: (8843, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_melgan_large.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/fake/ljspeech_melgan_large.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/fake/ljspeech_melgan_large.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35369, 1, 64, 64), Test: (8843, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_multi_band_melgan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/fake/ljspeech_multi_band_melgan.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/fake/ljspeech_multi_band_melgan.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35369, 1, 64, 64), Test: (8843, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_waveglow.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/fake/ljspeech_waveglow.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/fake/ljspeech_waveglow.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (35349, 1, 64, 64), Test: (8838, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_shape, test_shape = split_npy_file(\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32/normalized_real.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/train/real.npy',\n",
    "    '/home/ml/Documents/voice/ResData/wavefake32_2048split/test/real.npy',\n",
    "    train_ratio=0.8,\n",
    "    seed=42\n",
    ")\n",
    "print(f\"Train: {train_shape}, Test: {test_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- enhancing frequency domain!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# constants  (ONLY the first two lines changed)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "SR            = 16_000          # ← resample target is now 16 kHz\n",
    "SEGMENT_LEN   = 4 * SR          # 4-second chunks = 64 000 samples\n",
    "N_MELS        = 128\n",
    "N_FFT         = 2048\n",
    "HOP_LENGTH    = 512\n",
    "TARGET_FRAMES = 128\n",
    "MAX_PAD_RATIO = 0.65\n",
    "\n",
    "\n",
    "def load_audio(path: Path) -> np.ndarray:\n",
    "    \"\"\"Read WAV/FLAC/etc. → mono float32, then resample to 16 kHz.\"\"\"\n",
    "    audio, sr_in = sf.read(str(path))\n",
    "    if audio.ndim > 1:\n",
    "        audio = audio.mean(axis=1)           # mix to mono\n",
    "    if sr_in != SR:                          # resample if needed\n",
    "        audio = librosa.resample(audio,\n",
    "                                 orig_sr=sr_in,\n",
    "                                 target_sr=SR)\n",
    "    return audio.astype(np.float32)\n",
    "\n",
    "\n",
    "def wav_to_logmel(wav: np.ndarray) -> np.ndarray:\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=wav, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS, power=2.0,\n",
    "    )\n",
    "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "    if logmel.shape[1] != TARGET_FRAMES:\n",
    "        logmel = resize(\n",
    "            logmel, (N_MELS, TARGET_FRAMES),\n",
    "            mode=\"reflect\", preserve_range=True, anti_aliasing=True\n",
    "        )\n",
    "    return logmel.astype(np.float32)\n",
    "\n",
    "def full_logmel(wav: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Log-Mel spectrogram for the *entire* waveform.\n",
    "    Returns (N_MELS, T_frames) in dB.\n",
    "    \"\"\"\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=wav, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS, power=2.0,\n",
    "    )\n",
    "    return librosa.power_to_db(mel, ref=np.max).astype(np.float32)  # (128, T)\n",
    "\n",
    "\n",
    "def preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir: str | Path,\n",
    "    out_npy_file: str | Path,\n",
    "    out_stats_json: str | Path | None = None,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    wav_dir = Path(wav_dir)\n",
    "    tiles: list[np.ndarray] = []\n",
    "\n",
    "    for wav_path in wav_dir.rglob(\"*.wav\"):\n",
    "        wav = load_audio(wav_path)\n",
    "        logmel = full_logmel(wav)          # (128, T)\n",
    "        n_frames = logmel.shape[1]\n",
    "        n_chunks = math.ceil(n_frames / TARGET_FRAMES)\n",
    "\n",
    "        for i in range(n_chunks):\n",
    "            tile = logmel[:, i*TARGET_FRAMES:(i+1)*TARGET_FRAMES]\n",
    "            missing = TARGET_FRAMES - tile.shape[1]\n",
    "\n",
    "            if missing > 0:\n",
    "                pad_ratio = missing / TARGET_FRAMES\n",
    "                if pad_ratio > MAX_PAD_RATIO:\n",
    "                    continue  # skip overly short tail\n",
    "                # pad with the floor dB value so “silence” looks right\n",
    "                tile = np.pad(\n",
    "                    tile,\n",
    "                    pad_width=((0, 0), (0, missing)),\n",
    "                    mode=\"constant\",\n",
    "                    constant_values=-80.0,\n",
    "                )\n",
    "            tiles.append(tile[None, ...])   # (1,128,128)\n",
    "\n",
    "    if not tiles:\n",
    "        raise RuntimeError(f\"No usable segments found in {wav_dir}\")\n",
    "\n",
    "    data = np.stack(tiles, axis=0)          # (N,1,128,128) float32\n",
    "\n",
    "    # ── fixed-range scaling to [-1,1] ──────────────────────────\n",
    "    floor_db, ceil_db = -80.0, 0.0\n",
    "    data = np.clip(data, floor_db, ceil_db)\n",
    "    data = (data - floor_db) / (ceil_db - floor_db)   # → [0,1]\n",
    "    data = data * 2.0 - 1.0                          # → [-1,1]\n",
    "\n",
    "    # ── atomic save ────────────────────────────────────────────\n",
    "    out_npy_file = Path(out_npy_file)\n",
    "    out_npy_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(dir=out_npy_file.parent,\n",
    "                                     suffix=\".npy\", delete=False) as tmp:\n",
    "        np.save(tmp.name, data)\n",
    "        tmp.flush()\n",
    "        os.fsync(tmp.fileno())\n",
    "    os.replace(tmp.name, out_npy_file)\n",
    "\n",
    "    print(f\"✅ Saved {data.shape[0]} segments → {out_npy_file}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_full_band_melgan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_full_band_melgan.npy\"\n",
    ")\n",
    "\n",
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_hifiGAN\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_hifiGAN.npy\"\n",
    ")\n",
    "\n",
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_melgan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_melgan.npy\"\n",
    ")\n",
    "\n",
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_melgan_large\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_melgan_large.npy\"\n",
    ")\n",
    "\n",
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_multi_band_melgan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_multi_band_melgan.npy\"\n",
    ")\n",
    "\n",
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_parallel_wavegan\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_parallel_wavegan.npy\"\n",
    ")\n",
    "\n",
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/fake/ljspeech_waveglow\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/fake/normalized_ljspeech_waveglow.npy\"\n",
    ")\n",
    "\n",
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_wavefake/real/wavs\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/wavefake32/normalized_real.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 7649 segments → /home/ml/Documents/voice/ResData/ASV128/test/real.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[-0.6568533 , -0.7925539 , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.6125681 , -0.74188995, -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.49124545, -0.45326233, -0.38913214, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-0.65216905, -0.8166157 , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.54957044, -0.707338  , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.35180247, -0.39018136, -0.28695142, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-0.66001624, -0.8146402 , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.5788511 , -0.7309803 , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.29107016, -0.24404544, -0.25609177, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.91698647, -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.86953795, -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.7668797 , -0.7542965 , -0.63157046, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-0.6420803 , -0.8104803 , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.56473446, -0.7225939 , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.40403903, -0.41440898, -0.4211434 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-0.7815151 , -0.9451111 , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.72456014, -0.88909376, -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-0.45793533, -0.41998398, -0.42111838, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_logmel_to_npy_normalised(\n",
    "    wav_dir=\"/home/ml/Documents/voice/data_train/eval/real\",\n",
    "    out_npy_file=\"/home/ml/Documents/voice/ResData/ASV128/test/real.npy\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
