{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio files and saving Mel spectrograms...\n",
      "Original audio saved to output_mel_spectrograms/original_0.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_0.pt\n",
      "Original audio saved to output_mel_spectrograms/original_1.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_1.pt\n",
      "Original audio saved to output_mel_spectrograms/original_2.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_2.pt\n",
      "Original audio saved to output_mel_spectrograms/original_3.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_3.pt\n",
      "Original audio saved to output_mel_spectrograms/original_4.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_4.pt\n",
      "Original audio saved to output_mel_spectrograms/original_5.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_5.pt\n",
      "Original audio saved to output_mel_spectrograms/original_6.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_6.pt\n",
      "Original audio saved to output_mel_spectrograms/original_7.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_7.pt\n",
      "Original audio saved to output_mel_spectrograms/original_8.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_8.pt\n",
      "Original audio saved to output_mel_spectrograms/original_9.wav\n",
      "Mel spectrogram tensor saved to output_mel_spectrograms/mel_9.pt\n",
      "Total number of processed samples: 10\n",
      "Reconstructing audio from Mel spectrograms and plotting comparisons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_126265/645680620.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(tensor_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_0.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_0.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_1.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_1.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_2.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_2.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_3.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_3.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_4.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_4.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_5.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_5.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_6.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_6.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_7.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_7.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_8.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_8.png\n",
      "Reconstructed audio saved to output_mel_spectrograms/reconstructed_9.wav\n",
      "Mel spectrogram comparison plot saved to output_mel_spectrograms/mel_spectrogram_comparison_9.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Function to preprocess LibriSpeech dataset into Mel spectrograms and save them as tensors\n",
    "def librispeech_to_mel_and_save(\n",
    "    root_dir,\n",
    "    output_dir,\n",
    "    target_sr=16000,\n",
    "    n_mels=1024,       # Increased from 64 to 128 for higher frequency resolution\n",
    "    n_fft=8192,       # Increased from 1024 to 2048 for higher frequency resolution\n",
    "    hop_length=256,   # Decreased from 512 to 256 for higher time resolution\n",
    "    target_length=256 # Adjusted to accommodate the change in hop_length\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert LibriSpeech audio files to Mel spectrograms, save spectrograms as tensors, and save original audio.\n",
    "    \"\"\"\n",
    "    flac_files = glob.glob(os.path.join(root_dir, \"**\", \"*.flac\"), recursive=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "    mel_spectrograms = []  # To store Mel spectrogram tensors\n",
    "\n",
    "    if len(flac_files) == 0:\n",
    "        raise ValueError(f\"No FLAC files found in directory: {root_dir}\")\n",
    "\n",
    "    for i, file in enumerate(flac_files[:10]):  # Process only the first 10 files\n",
    "        try:\n",
    "            # Load the audio file\n",
    "            audio, sr = librosa.load(file, sr=target_sr)\n",
    "            audio = audio / np.max(np.abs(audio))  # Normalize audio to [-1, 1]\n",
    "\n",
    "            # Save the original audio\n",
    "            audio_output_path = os.path.join(output_dir, f\"original_{i}.wav\")\n",
    "            sf.write(audio_output_path, audio, sr)\n",
    "            print(f\"Original audio saved to {audio_output_path}\")\n",
    "\n",
    "            # Convert to Mel spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=audio,\n",
    "                sr=sr,\n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                n_mels=n_mels,\n",
    "                power=1.0,\n",
    "            )\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "            # Normalize using fixed range [mel_spec_db.min(), 0] to [-1, 1]\n",
    "            min_db = mel_spec_db.min()\n",
    "            mel_spec_db_norm = (mel_spec_db - min_db) / -min_db  # Normalize to [0, 1]\n",
    "            mel_spec_db_norm = mel_spec_db_norm * 2 - 1           # Scale to [-1, 1]\n",
    "\n",
    "            # Ensure the Mel spectrogram has a fixed length\n",
    "            if mel_spec_db_norm.shape[1] < target_length:\n",
    "                pad_width = target_length - mel_spec_db_norm.shape[1]\n",
    "                mel_spec_db_norm = np.pad(\n",
    "                    mel_spec_db_norm, ((0, 0), (0, pad_width)), mode=\"constant\"\n",
    "                )\n",
    "            else:\n",
    "                mel_spec_db_norm = mel_spec_db_norm[:, :target_length]\n",
    "\n",
    "            # Save the Mel spectrogram as a tensor\n",
    "            tensor_output_path = os.path.join(output_dir, f\"mel_{i}.pt\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    'mel_spec_db_norm': torch.tensor(mel_spec_db_norm, dtype=torch.float32),\n",
    "                    'min_db': min_db  # Save min_db for de-normalization\n",
    "                },\n",
    "                tensor_output_path\n",
    "            )\n",
    "            print(f\"Mel spectrogram tensor saved to {tensor_output_path}\")\n",
    "\n",
    "            # Add to the list of tensors\n",
    "            mel_spectrograms.append(\n",
    "                torch.tensor(mel_spec_db_norm, dtype=torch.float32).unsqueeze(0)\n",
    "            )  # Add channel dim\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    if len(mel_spectrograms) == 0:\n",
    "        raise ValueError(\n",
    "            \"No valid audio files were processed into Mel spectrograms.\"\n",
    "        )\n",
    "\n",
    "    # Return TensorDataset of Mel spectrograms\n",
    "    mel_spectrograms = torch.stack(\n",
    "        mel_spectrograms\n",
    "    )  # Shape: [num_samples, 1, n_mels, target_length]\n",
    "    return TensorDataset(mel_spectrograms)\n",
    "\n",
    "\n",
    "def reconstruct_audio_from_mel_tensors(\n",
    "    output_dir,\n",
    "    target_sr=16000,\n",
    "    n_fft=8192,\n",
    "    hop_length=256,\n",
    "    n_iter=500,  # Increased iterations for better phase estimation\n",
    "    target_length=256,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reconstruct audio from Mel spectrogram tensors and save as WAV, ensuring correct length and preserving amplitude.\n",
    "    \"\"\"\n",
    "    tensor_files = glob.glob(os.path.join(output_dir, \"mel_*.pt\"))\n",
    "    tensor_files.sort()  # Ensure consistent order\n",
    "\n",
    "    for i, tensor_file in enumerate(tensor_files):\n",
    "        try:\n",
    "            # Load the Mel spectrogram tensor\n",
    "            data = torch.load(tensor_file)\n",
    "            mel_spec_db_norm = data['mel_spec_db_norm'].numpy()\n",
    "            min_db = data['min_db']\n",
    "\n",
    "            # De-normalize from [-1, 1] back to the dB range\n",
    "            mel_spec_db = (mel_spec_db_norm + 1) / 2  # Scale to [0, 1]\n",
    "            mel_spec_db = mel_spec_db * -min_db + min_db  # Scale back to original dB range\n",
    "\n",
    "            # Convert dB back to power\n",
    "            mel_spec_power = librosa.db_to_power(mel_spec_db)  # Convert to power scale\n",
    "\n",
    "            # Reconstruct audio from Mel spectrogram\n",
    "            audio = librosa.feature.inverse.mel_to_audio(\n",
    "                mel_spec_power,\n",
    "                sr=target_sr,\n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                n_iter=n_iter,\n",
    "                power=1.0,\n",
    "            )\n",
    "\n",
    "            # Match amplitude to original audio\n",
    "            original_audio_path = os.path.join(output_dir, f\"original_{i}.wav\")\n",
    "            original_audio, _ = librosa.load(original_audio_path, sr=target_sr)\n",
    "\n",
    "            # Compute RMS of original and reconstructed audio\n",
    "            original_rms = np.sqrt(np.mean(original_audio**2))\n",
    "            reconstructed_rms = np.sqrt(np.mean(audio**2))\n",
    "\n",
    "            if reconstructed_rms > 0:  # Prevent division by zero\n",
    "                audio = audio * (original_rms / reconstructed_rms)\n",
    "\n",
    "            # Ensure the audio matches the expected length\n",
    "            expected_length = target_length * hop_length\n",
    "            audio = librosa.util.fix_length(audio, size=expected_length)\n",
    "\n",
    "            # Save the reconstructed audio\n",
    "            reconstructed_audio_path = os.path.join(\n",
    "                output_dir, f\"reconstructed_{i}.wav\"\n",
    "            )\n",
    "            sf.write(reconstructed_audio_path, audio, target_sr)\n",
    "            print(f\"Reconstructed audio saved to {reconstructed_audio_path}\")\n",
    "\n",
    "            # Plot Mel spectrograms for comparison\n",
    "            plot_mel_spectrograms_comparison(\n",
    "                original_audio_path,\n",
    "                reconstructed_audio_path,\n",
    "                sr=target_sr,\n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                n_mels=1024,  # Adjusted to match input\n",
    "                i=i,\n",
    "                output_dir=output_dir,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reconstructing audio from file {tensor_file}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_mel_spectrograms_comparison(original_audio_path, reconstructed_audio_path, sr, n_fft, hop_length, n_mels, i, output_dir):\n",
    "    \"\"\"\n",
    "    Plot and save Mel spectrograms of the original and reconstructed audio for comparison.\n",
    "    \"\"\"\n",
    "    # Load original and reconstructed audio\n",
    "    original_audio, _ = librosa.load(original_audio_path, sr=sr)\n",
    "    reconstructed_audio, _ = librosa.load(reconstructed_audio_path, sr=sr)\n",
    "\n",
    "    # Match lengths of original and reconstructed audio\n",
    "    min_length = min(len(original_audio), len(reconstructed_audio))\n",
    "    original_audio = original_audio[:min_length]\n",
    "    reconstructed_audio = reconstructed_audio[:min_length]\n",
    "\n",
    "    # Compute Mel spectrograms\n",
    "    original_mel_spec = librosa.feature.melspectrogram(\n",
    "        y=original_audio,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        power=1.0,\n",
    "    )\n",
    "    original_mel_spec_db = librosa.power_to_db(original_mel_spec, ref=np.max)\n",
    "\n",
    "    reconstructed_mel_spec = librosa.feature.melspectrogram(\n",
    "        y=reconstructed_audio,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        power=1.0,\n",
    "    )\n",
    "    reconstructed_mel_spec_db = librosa.power_to_db(reconstructed_mel_spec, ref=np.max)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    img1 = librosa.display.specshow(\n",
    "        original_mel_spec_db,\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        sr=sr,\n",
    "        hop_length=hop_length,\n",
    "        ax=axs[0]\n",
    "    )\n",
    "    axs[0].set_title(f'Original Audio Mel Spectrogram {i}')\n",
    "    fig.colorbar(img1, ax=axs[0], format='%+2.0f dB')\n",
    "\n",
    "    img2 = librosa.display.specshow(\n",
    "        reconstructed_mel_spec_db,\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        sr=sr,\n",
    "        hop_length=hop_length,\n",
    "        ax=axs[1]\n",
    "    )\n",
    "    axs[1].set_title(f'Reconstructed Audio Mel Spectrogram {i}')\n",
    "    fig.colorbar(img2, ax=axs[1], format='%+2.0f dB')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(output_dir, f'mel_spectrogram_comparison_{i}.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close(fig)\n",
    "    print(f'Mel spectrogram comparison plot saved to {plot_path}')\n",
    "\n",
    "\n",
    "\n",
    "# Main Function\n",
    "def main():\n",
    "    data_dir = r\"data/LibriSpeech/LibriSpeech/dev-clean\"  # Input directory with audio files\n",
    "    output_dir = r\"output_mel_spectrograms\"  # Output directory for spectrograms and reconstructed audio\n",
    "\n",
    "    # Step 1: Convert audio to Mel spectrograms and save\n",
    "    print(\"Processing audio files and saving Mel spectrograms...\")\n",
    "    mel_dataset = librispeech_to_mel_and_save(data_dir, output_dir)\n",
    "    print(f\"Total number of processed samples: {len(mel_dataset)}\")\n",
    "\n",
    "    # Step 2: Reconstruct audio from saved Mel spectrograms and plot comparisons\n",
    "    print(\"Reconstructing audio from Mel spectrograms and plotting comparisons...\")\n",
    "    reconstruct_audio_from_mel_tensors(output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
